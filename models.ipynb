{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 74,
            "source": [
                "from __future__ import print_function\n",
                "import keras\n",
                "from keras.preprocessing.image import ImageDataGenerator\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
                "from keras.layers import Conv2D,MaxPooling2D\n",
                "import os\n",
                "import numpy as np \n",
                "import scipy\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "source": [
                "num_classes=6\n",
                "img_rows,img_cols=48,48\n",
                "batch_size=32\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "source": [
                "train_data_dir='fer2013/train'\n",
                "validation_data_dir='fer2013/validation'\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "source": [
                "train_datagen = ImageDataGenerator(\n",
                "\t\t\t\t\trescale=1./255,\n",
                "\t\t\t\t\trotation_range=30,\n",
                "\t\t\t\t\tshear_range=0.3,\n",
                "\t\t\t\t\tzoom_range=0.3,\n",
                "\t\t\t\t\twidth_shift_range=0.4,\n",
                "\t\t\t\t\theight_shift_range=0.4,\n",
                "\t\t\t\t\thorizontal_flip=True,\n",
                "\t\t\t\t\tfill_mode='nearest')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "source": [
                "validation_datagen = ImageDataGenerator(rescale=1./255)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "source": [
                "\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "\t\t\t\t\ttrain_data_dir,\n",
                "\t\t\t\t\tcolor_mode='grayscale',\n",
                "\t\t\t\t\ttarget_size=(img_rows,img_cols),\n",
                "\t\t\t\t\tbatch_size=batch_size,\n",
                "\t\t\t\t\tclass_mode='categorical',\n",
                "\t\t\t\t\tshuffle=True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Found 28353 images belonging to 6 classes.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "source": [
                "validation_generator = validation_datagen.flow_from_directory(\n",
                "\t\t\t\t\t\t\tvalidation_data_dir,\n",
                "\t\t\t\t\t\t\tcolor_mode='grayscale',\n",
                "\t\t\t\t\t\t\ttarget_size=(img_rows,img_cols),\n",
                "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
                "\t\t\t\t\t\t\tclass_mode='categorical',\n",
                "\t\t\t\t\t\t\tshuffle=True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Found 3534 images belonging to 6 classes.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "source": [
                "\n",
                "model = Sequential()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "source": [
                "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(MaxPooling2D(pool_size=(2,2)))\n",
                "model.add(Dropout(0.2))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "source": [
                "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(MaxPooling2D(pool_size=(2,2)))\n",
                "model.add(Dropout(0.2))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "source": [
                "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(MaxPooling2D(pool_size=(2,2)))\n",
                "model.add(Dropout(0.2))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "source": [
                "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(MaxPooling2D(pool_size=(2,2)))\n",
                "model.add(Dropout(0.2))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "source": [
                "\n",
                "model.add(Flatten())\n",
                "model.add(Dense(64,kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Dropout(0.5))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "source": [
                "model.add(Dense(64,kernel_initializer='he_normal'))\n",
                "model.add(Activation('elu'))\n",
                "model.add(BatchNormalization())\n",
                "model.add(Dropout(0.5))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "source": [
                "\n",
                "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
                "model.add(Activation('softmax'))\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "source": [
                "\n",
                "print(model.summary())"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Model: \"sequential_2\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "conv2d_16 (Conv2D)           (None, 48, 48, 32)        320       \n",
                        "_________________________________________________________________\n",
                        "activation_22 (Activation)   (None, 48, 48, 32)        0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_20 (Batc (None, 48, 48, 32)        128       \n",
                        "_________________________________________________________________\n",
                        "conv2d_17 (Conv2D)           (None, 48, 48, 32)        9248      \n",
                        "_________________________________________________________________\n",
                        "activation_23 (Activation)   (None, 48, 48, 32)        0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_21 (Batc (None, 48, 48, 32)        128       \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_8 (MaxPooling2 (None, 24, 24, 32)        0         \n",
                        "_________________________________________________________________\n",
                        "dropout_12 (Dropout)         (None, 24, 24, 32)        0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_18 (Conv2D)           (None, 24, 24, 64)        18496     \n",
                        "_________________________________________________________________\n",
                        "activation_24 (Activation)   (None, 24, 24, 64)        0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_22 (Batc (None, 24, 24, 64)        256       \n",
                        "_________________________________________________________________\n",
                        "conv2d_19 (Conv2D)           (None, 24, 24, 64)        36928     \n",
                        "_________________________________________________________________\n",
                        "activation_25 (Activation)   (None, 24, 24, 64)        0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_23 (Batc (None, 24, 24, 64)        256       \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
                        "_________________________________________________________________\n",
                        "dropout_13 (Dropout)         (None, 12, 12, 64)        0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_20 (Conv2D)           (None, 12, 12, 128)       73856     \n",
                        "_________________________________________________________________\n",
                        "activation_26 (Activation)   (None, 12, 12, 128)       0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_24 (Batc (None, 12, 12, 128)       512       \n",
                        "_________________________________________________________________\n",
                        "conv2d_21 (Conv2D)           (None, 12, 12, 128)       147584    \n",
                        "_________________________________________________________________\n",
                        "activation_27 (Activation)   (None, 12, 12, 128)       0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_25 (Batc (None, 12, 12, 128)       512       \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_10 (MaxPooling (None, 6, 6, 128)         0         \n",
                        "_________________________________________________________________\n",
                        "dropout_14 (Dropout)         (None, 6, 6, 128)         0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_22 (Conv2D)           (None, 6, 6, 256)         295168    \n",
                        "_________________________________________________________________\n",
                        "activation_28 (Activation)   (None, 6, 6, 256)         0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_26 (Batc (None, 6, 6, 256)         1024      \n",
                        "_________________________________________________________________\n",
                        "conv2d_23 (Conv2D)           (None, 6, 6, 256)         590080    \n",
                        "_________________________________________________________________\n",
                        "activation_29 (Activation)   (None, 6, 6, 256)         0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_27 (Batc (None, 6, 6, 256)         1024      \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_11 (MaxPooling (None, 3, 3, 256)         0         \n",
                        "_________________________________________________________________\n",
                        "dropout_15 (Dropout)         (None, 3, 3, 256)         0         \n",
                        "_________________________________________________________________\n",
                        "flatten_2 (Flatten)          (None, 2304)              0         \n",
                        "_________________________________________________________________\n",
                        "dense_6 (Dense)              (None, 64)                147520    \n",
                        "_________________________________________________________________\n",
                        "activation_30 (Activation)   (None, 64)                0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_28 (Batc (None, 64)                256       \n",
                        "_________________________________________________________________\n",
                        "dropout_16 (Dropout)         (None, 64)                0         \n",
                        "_________________________________________________________________\n",
                        "dense_7 (Dense)              (None, 64)                4160      \n",
                        "_________________________________________________________________\n",
                        "activation_31 (Activation)   (None, 64)                0         \n",
                        "_________________________________________________________________\n",
                        "batch_normalization_29 (Batc (None, 64)                256       \n",
                        "_________________________________________________________________\n",
                        "dropout_17 (Dropout)         (None, 64)                0         \n",
                        "_________________________________________________________________\n",
                        "dense_8 (Dense)              (None, 6)                 390       \n",
                        "_________________________________________________________________\n",
                        "activation_32 (Activation)   (None, 6)                 0         \n",
                        "=================================================================\n",
                        "Total params: 1,328,102\n",
                        "Trainable params: 1,325,926\n",
                        "Non-trainable params: 2,176\n",
                        "_________________________________________________________________\n",
                        "None\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "source": [
                "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
                "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "source": [
                "checkpoint = ModelCheckpoint('EmotionDetectionModel.h5',\n",
                "                             monitor='val_loss',\n",
                "                             mode='min',\n",
                "                             save_best_only=True,\n",
                "                             verbose=1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "source": [
                "earlystop = EarlyStopping(monitor='val_loss',\n",
                "                          min_delta=0,\n",
                "                          patience=3,\n",
                "                          verbose=1,\n",
                "                          restore_best_weights=True\n",
                "                          )"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "source": [
                "\n",
                "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
                "                              factor=0.2,\n",
                "                              patience=3,\n",
                "                              verbose=1,\n",
                "                              min_delta=0.0001)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "source": [
                "callbacks = [earlystop,checkpoint,reduce_lr]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "source": [
                "model.compile(loss='categorical_crossentropy',\n",
                "              optimizer = Adam(lr=0.001),\n",
                "              metrics=['accuracy'])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "source": [
                "nb_train_samples = 24176\n",
                "nb_validation_samples = 3006\n",
                "epochs=25\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "source": [
                "history=model.fit_generator(\n",
                "                train_generator,\n",
                "                steps_per_epoch=nb_train_samples//batch_size,\n",
                "                epochs=epochs,\n",
                "                callbacks=callbacks,\n",
                "                validation_data=validation_generator,\n",
                "                validation_steps=nb_validation_samples//batch_size)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1/25\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-20 16:09:31.949180: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 26542080 exceeds 10% of free system memory.\n",
                        "2021-08-20 16:09:31.950774: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 26542080 exceeds 10% of free system memory.\n",
                        "2021-08-20 16:09:32.065656: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 29196288 exceeds 10% of free system memory.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "  1/755 [..............................] - ETA: 29:53 - loss: 2.6354 - accuracy: 0.2188"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-20 16:09:32.460136: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 26542080 exceeds 10% of free system memory.\n",
                        "2021-08-20 16:09:32.460643: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 26542080 exceeds 10% of free system memory.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "755/755 [==============================] - 370s 488ms/step - loss: 2.0604 - accuracy: 0.2016 - val_loss: 1.7369 - val_accuracy: 0.2527\n",
                        "\n",
                        "Epoch 00001: val_loss improved from inf to 1.73695, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 2/25\n",
                        "755/755 [==============================] - 370s 487ms/step - loss: 1.7653 - accuracy: 0.2414 - val_loss: 1.7272 - val_accuracy: 0.2628\n",
                        "\n",
                        "Epoch 00002: val_loss improved from 1.73695 to 1.72717, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 3/25\n",
                        "755/755 [==============================] - 243s 322ms/step - loss: 1.7381 - accuracy: 0.2581 - val_loss: 1.7467 - val_accuracy: 0.2621\n",
                        "\n",
                        "Epoch 00003: val_loss did not improve from 1.72717\n",
                        "Epoch 4/25\n",
                        "755/755 [==============================] - 234s 310ms/step - loss: 1.7310 - accuracy: 0.2582 - val_loss: 1.7110 - val_accuracy: 0.2782\n",
                        "\n",
                        "Epoch 00004: val_loss improved from 1.72717 to 1.71101, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 5/25\n",
                        "755/755 [==============================] - 235s 311ms/step - loss: 1.7114 - accuracy: 0.2747 - val_loss: 1.6301 - val_accuracy: 0.3290\n",
                        "\n",
                        "Epoch 00005: val_loss improved from 1.71101 to 1.63009, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 6/25\n",
                        "755/755 [==============================] - 235s 311ms/step - loss: 1.6583 - accuracy: 0.3105 - val_loss: 1.5462 - val_accuracy: 0.3858\n",
                        "\n",
                        "Epoch 00006: val_loss improved from 1.63009 to 1.54622, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 7/25\n",
                        "755/755 [==============================] - 235s 312ms/step - loss: 1.5793 - accuracy: 0.3525 - val_loss: 1.5671 - val_accuracy: 0.3622\n",
                        "\n",
                        "Epoch 00007: val_loss did not improve from 1.54622\n",
                        "Epoch 8/25\n",
                        "755/755 [==============================] - 235s 311ms/step - loss: 1.5123 - accuracy: 0.3944 - val_loss: 1.5051 - val_accuracy: 0.4022\n",
                        "\n",
                        "Epoch 00008: val_loss improved from 1.54622 to 1.50509, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 9/25\n",
                        "755/755 [==============================] - 234s 310ms/step - loss: 1.4585 - accuracy: 0.4168 - val_loss: 1.5118 - val_accuracy: 0.4382\n",
                        "\n",
                        "Epoch 00009: val_loss did not improve from 1.50509\n",
                        "Epoch 10/25\n",
                        "755/755 [==============================] - 235s 311ms/step - loss: 1.4180 - accuracy: 0.4396 - val_loss: 1.4527 - val_accuracy: 0.4496\n",
                        "\n",
                        "Epoch 00010: val_loss improved from 1.50509 to 1.45274, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 11/25\n",
                        "755/755 [==============================] - 235s 311ms/step - loss: 1.3955 - accuracy: 0.4484 - val_loss: 1.4462 - val_accuracy: 0.4553\n",
                        "\n",
                        "Epoch 00011: val_loss improved from 1.45274 to 1.44618, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 12/25\n",
                        "755/755 [==============================] - 234s 310ms/step - loss: 1.3666 - accuracy: 0.4608 - val_loss: 1.5286 - val_accuracy: 0.4526\n",
                        "\n",
                        "Epoch 00012: val_loss did not improve from 1.44618\n",
                        "Epoch 13/25\n",
                        "755/755 [==============================] - 236s 312ms/step - loss: 1.3521 - accuracy: 0.4718 - val_loss: 1.4854 - val_accuracy: 0.4724\n",
                        "\n",
                        "Epoch 00013: val_loss did not improve from 1.44618\n",
                        "Epoch 14/25\n",
                        "755/755 [==============================] - 236s 312ms/step - loss: 1.3397 - accuracy: 0.4762 - val_loss: 1.4460 - val_accuracy: 0.4684\n",
                        "\n",
                        "Epoch 00014: val_loss improved from 1.44618 to 1.44603, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 15/25\n",
                        "755/755 [==============================] - 234s 310ms/step - loss: 1.3228 - accuracy: 0.4846 - val_loss: 1.4175 - val_accuracy: 0.4741\n",
                        "\n",
                        "Epoch 00015: val_loss improved from 1.44603 to 1.41753, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 16/25\n",
                        "755/755 [==============================] - 235s 311ms/step - loss: 1.3104 - accuracy: 0.4853 - val_loss: 1.3894 - val_accuracy: 0.4909\n",
                        "\n",
                        "Epoch 00016: val_loss improved from 1.41753 to 1.38937, saving model to EmotionDetectionModel.h5\n",
                        "Epoch 17/25\n",
                        "755/755 [==============================] - 236s 313ms/step - loss: 1.3046 - accuracy: 0.4930 - val_loss: 1.3896 - val_accuracy: 0.5040\n",
                        "\n",
                        "Epoch 00017: val_loss did not improve from 1.38937\n",
                        "Epoch 18/25\n",
                        "755/755 [==============================] - 237s 314ms/step - loss: 1.2883 - accuracy: 0.4955 - val_loss: 1.3975 - val_accuracy: 0.5060\n",
                        "\n",
                        "Epoch 00018: val_loss did not improve from 1.38937\n",
                        "Epoch 19/25\n",
                        "755/755 [==============================] - 236s 312ms/step - loss: 1.2837 - accuracy: 0.5042 - val_loss: 1.4754 - val_accuracy: 0.5064\n",
                        "Restoring model weights from the end of the best epoch.\n",
                        "\n",
                        "Epoch 00019: val_loss did not improve from 1.38937\n",
                        "\n",
                        "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
                        "Epoch 00019: early stopping\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('new_env': venv)"
        },
        "interpreter": {
            "hash": "d0871e386e9efa878d3d9af42d5ac3260ccaf45af1130d69a728e963ddf35bae"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}